# Language Analytics Assignment 4
## Assignment description
This repository contains my solutions to assignment 4 for the Language Analytics course at Aarhus university. The goal of this assignment is to write to programs that can classify weather or not a particular youtube comment is toxic or not in two different ways – one should provide a benchmark using a logistic classifier, while the other should use word embeddings fed into a convolutional neural network.     
Analysis was carried out using data from (Hammer et al., 2019).    

## Methods
For the logistic classifier, the script balances the data, then splits it into test and training data, then vectorizes and classifies it. 
For the neural network, the script again balances the data and splits it, but afterwards it tokenizes the text, pads it, builds the model, and runs it for a user-defined number of epochs.     

## Repository structure
in: Folder for input data    
notebooks: Folder for experimental code    
output: Folder for the output generated by the scrips – at present it contains 4 files:    
- CNN_report.txt:
    -Output of the cnn_classifer.py script – txt file containing the classification report for the CNN
- history_img.csv:
    - Generated by running cnn_classifier.py – an image containing two graphs – one that tracks the training and validation loss across epochs, and one that does the same for the training and validation accuracy
- logistic_report.txt:
    - Output of the logistic_classifier.py script – txt file containing the classification report for the logistic classifier

src: Folder for python scripts    
- \_\_init__.py
- cnn_classifier.py
- logistic_classifier.py

github_link.txt: link to github repository    
requirements.txt: txt file containing the modules required to run the code    

## Usage
Modules listed in requirements.txt should be installed before scripts are run.    
__Input data__    
The input data for both scripts should be a csv file containing at leas two colums. One named "text" containing the text to be analyzed, and one named "label" containing the label fo the text, either "Toxic" or "Nontoxic".    
__cnn_classifier.py__    
To classify the data using a CNN, run cnn_classifier.py from the Language_analytics_A4 repository folder. The script has two arguments:    
-	_-s or --split: Proportion of the data that goes into the test dataset - default is 0.2_    
-	_-e or --epochs: Nr. of epochs for the CNN to run - default is 10_    

Example of code running the script from the terminal:    
```
python src/cnn_classifier.py -s 0.2 -e 10
```

__logistic_classifier.py__    
To classify the data using a logistic classifier, run logistic_classifier.py from the Language_analytics_A4 repository folder. The script has four arguments:    
-	_-s or --split: Proportion of the data that goes into the test dataset - default is 0.2_
-	_-max or --max_df: Threshold for removal of the most common words in sequence - default is 0.95_
-	_-min or –min_df: Threshold for removal of the least common words in sequence - default is 0.05_
-	_-f or –max_features: Max nr. of features after vectorizing - default is 500_

Example of code running the script from the terminal:    
```
python src/logistic_classifer.py -s 0.4 -max 0.95 -min 0.05 -f 500
```

## Discussion of results
I ran the script with all the arguments at default.     
Looking at the classification reports, the logistic classifier seems to do better than the CNN classifier by far. Looking at history_img.png, it seems like it might have something to do with overfitting, as validation- and training-accuracy and -loss diverge fairly early on in the process of fitting the model.     

## Citations
-	Hammer, H. L., Riegler, M. A., Ovrelid, L., & Velldal, E. (2019). THREAT: A Large Annotated Corpus for Detection of Violent Threats. 2019 International Conference on Content-Based Multimedia Indexing (CBMI), 1–5. https://doi.org/10.1109/CBMI.2019.8877435

